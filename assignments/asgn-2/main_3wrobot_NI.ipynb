{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "320d66ac",
   "metadata": {},
   "source": [
    "<h1 style=\"color:#A7BD3F; text-align:center; line-height: 0;\"> Advanced Control | Assignment 2 </h1>\n",
    "\n",
    "<br/><br/>\n",
    "\n",
    "**First install [Rcognita](https://github.com/AIDynamicAction/rcognita) if you have not already done so. In this case go to Section 1 and execute the cell.**\n",
    "\n",
    "In this assignment you will implement a classic MPC controller in the section 1.2, namely, `_actor_cost` and `_actor_optimizer` methods.\n",
    "\n",
    "For correct work this assignment requires the following files:\n",
    "* Of course, the notebook itself\n",
    "* asgn_2_stub.py - a module contains default arguments of preset configuration and base controller class\n",
    "* grading_utilities.py - grading utilities :)\n",
    "***\n",
    "To guarantee the proper work of the assignment notebook, move all these files into `rcognita/rcognita` path\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e27e0af1",
   "metadata": {},
   "source": [
    "<h2 style=\"color:#A7BD3F;\"> Section 0: Rcognita installation </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e39b539",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install rcognita"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7475032d",
   "metadata": {},
   "source": [
    "<h2 style=\"color:#A7BD3F;\"> Section 1: Main part </h2>\n",
    "\n",
    "***\n",
    "\n",
    "###  <font color=\"blue\"> 1.0 Mathematical statement recap </font>\n",
    "The main objective here is to keep the state of a deterministic system close to the origin of the state space\n",
    "or close to a given trajectory.\n",
    "\n",
    "$x$ - state from **state space** $\\mathbb{X}$\n",
    "\n",
    "$u$ - action from **action space** $\\mathbb{U}$\n",
    "\n",
    "$\\kappa$ - **policy**\n",
    "\n",
    "**Discrete time deterministic system (DT):**\n",
    "\n",
    "$x_{i+1} = f(x_i, u_i)$\n",
    "\n",
    "$u_i = \\kappa(x_i)$\n",
    "\n",
    "$l$-**stage optimal control problem:**\n",
    "\n",
    "$\\min _{u_{i}: i=k, \\ldots, k+\\ell-1} \\left(\\sum_{i=k}^{k+\\ell-1} g_{i}\\left(x_{i}, u_{i}\\right)\\right)$\n",
    "\n",
    "**Constraints:**\n",
    "\n",
    "$x_{i} \\in X, \\quad u_{i} \\in \\mathbb{U}, \\quad i=k, \\ldots, k+\\ell-1, \\quad x_{k+l}=0$\n",
    "\n",
    "We also assume that the system can be kept at the origin at zero cost, i.e.,\n",
    "\n",
    "$f_{k}\\left(0, \\bar{u}_{k}\\right)=0, \\quad g_{k}\\left(0, \\bar{u}_{k}\\right)=0 \\quad$ for some control  $\\quad \\bar{u}_{k} \\in \\mathbb{U}$\n",
    "\n",
    "#### Algorithm <sup>[1]</sup>:\n",
    "Let us describe the MPC algorithm for the deterministic problem just described above.  \n",
    "At the current state $x_{k}$ :\n",
    "\n",
    "(a) **MPC** solves an $\\ell$-step lookahead version of the problem, which requires that $x_{k+\\ell}=0$. \n",
    "\n",
    "(b) If $\\left\\{u^*_{k}, \\ldots, u^*_{k+\\ell-1}\\right\\}$ is the optimal control sequence of this problem, MPC applies $u^*_{k}$ and discards the other controls $u^*_{k+1}, \\ldots, u^*_{k+\\ell-1}$. \n",
    "\n",
    "(c) At the next stage, MPC repeats this process, once the next state $x_{k+1}$ is revealed.\n",
    "\n",
    "<img src=\"mpc.png\" width=60% height=60% />\n",
    "\n",
    "For a given initial state $x_{0} \\in \\mathbb{X}$, we want to obtain a sequence $\\left\\{u_{0}, u_{1}, \\ldots\\right\\}$ such that the states and controls of the system satisfy the state and control constraints with small total cost.\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0155532e",
   "metadata": {},
   "source": [
    "### <font color=\"blue\"> 1.1 Preparation. </font>\n",
    "Execute a code and verify that you're using rcognita located in cloned repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a67786",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DO NOT MODIFY\n",
    "\"\"\"\n",
    "notebook_name = \"main_3wrobot_NI.ipynb\"\n",
    "import os, sys\n",
    "__file__ = os.path.join(os.getcwd(),notebook_name)\n",
    "PARENT_DIR = os.path.abspath(__file__ + '/../..')\n",
    "sys.path.insert(0, PARENT_DIR)\n",
    "\n",
    "import rcognita\n",
    "\n",
    "if os.path.abspath(rcognita.__file__ + \"/../..\") == PARENT_DIR:\n",
    "    info = f\"this script is being run using \" \\\n",
    "           f\"rcognita ({rcognita.__version__}) \" \\\n",
    "           f\"located in cloned repository at '{PARENT_DIR}'. \" \\\n",
    "           f\"If you are willing to use your locally installed rcognita, \" \\\n",
    "           f\"run this script ('{os.path.basename(__file__)}') outside \" \\\n",
    "           f\"'rcognita/presets'.\"\n",
    "else:\n",
    "    info = f\"this script is being run using \" \\\n",
    "           f\"locally installed rcognita ({rcognita.__version__}). \" \\\n",
    "           f\"Make sure the versions match.\"\n",
    "print(\"INFO:\", info)\n",
    "\n",
    "import pathlib\n",
    "    \n",
    "import warnings\n",
    "import csv\n",
    "from datetime import datetime\n",
    "import matplotlib.animation as animation\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from grading_utilities import AnswerTracker\n",
    "from rcognita import simulator\n",
    "from rcognita import systems\n",
    "from rcognita import controllers\n",
    "from rcognita import loggers\n",
    "from rcognita import visuals\n",
    "from rcognita.utilities import on_key_press\n",
    "from utilities import dss_sim\n",
    "from utilities import rep_mat\n",
    "from utilities import uptria2vec\n",
    "from utilities import push_vec\n",
    "from asgn_2_stub import parser, CtrlOptPredBase\n",
    "\n",
    "%matplotlib notebook\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "512495ac",
   "metadata": {},
   "source": [
    "### <font color=\"blue\"> 1.2 Controller implementation </font>\n",
    "In this section you will have to implement 2 missing MPC controller methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffcf6875",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CtrlOptPred(CtrlOptPredBase):         \n",
    "    \"\"\"\n",
    "    CtrlOptPred class inherits from the CtrlOptPredBase class \n",
    "    in wich all methods needed for proper testing are already implemented. \n",
    "    \"\"\"\n",
    "    def _actor_cost(self, action_sqn, observation):\n",
    "        \n",
    "        my_action_sqn = np.reshape(action_sqn, [self.Nactor, self.dim_input])#ToDo: your code is here.\n",
    "        \n",
    "        observation_sqn = np.zeros([self.Nactor, self.dim_output])#ToDo: your code is here.\n",
    "        \n",
    "        # System output prediction\n",
    "        observation_sqn[0, :] = observation\n",
    "        state = self.state_sys\n",
    "        \n",
    "        \"\"\"\n",
    "        Implement cost computation in the following cycle. \n",
    "        Hint: Use self.sys_rhs as a reference to the right-hand-side of the system.\n",
    "        You can use Euler schema for numerical integration\n",
    "        \"\"\"\n",
    "        for k in range(1, self.Nactor): \n",
    "            state = #ToDo: your code is here.\n",
    "            \n",
    "            observation_sqn[k, :] = self.sys_out(state)\n",
    "        \"\"\"\n",
    "        Loop for calculation of objective \n",
    "        \"\"\"\n",
    "        J = 0\n",
    "        for k in range(self.Nactor):\n",
    "            #ToDo: your code is here.\n",
    "            \n",
    "        return J\n",
    "    \n",
    "    def _actor_optimizer(self, observation): \n",
    "        \"\"\"\n",
    "        Using scipy optimize ('SLSQP' optimization method), implement minimizer for ._actor_cost() function.\n",
    "        Carefully examine docs, choose suitable parameters and assign a dict with parameters to actor_opt_options.\n",
    "        \n",
    "        Set method of minimization to 'SLSQP'\n",
    "        Next, convert self.action_sqn_min to a proper dimentionality.\n",
    "        Create bounds for action.\n",
    "        Create minimizer instance and assign argmin from minimizer to action_sqn \n",
    "        Return the first action\n",
    "        \"\"\"\n",
    "        \n",
    "        my_action_sqn_init = #ToDo: your code is here.\n",
    "        \n",
    "        bnds = #ToDo: your code is here.\n",
    "        \n",
    "        action_sqn = #ToDo: your code is here.        \n",
    "\n",
    "        return #ToDo: your code is here. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2672368",
   "metadata": {},
   "source": [
    "<h2 style=\"color:#A7BD3F;\"> Section 2: Simulation </h2>\n",
    "\n",
    "### <font color=\"blue\"> 2.1 Preset: a 3-wheel robot (kinematic model a. k. a. non-holonomic integrator). </font>\n",
    "\n",
    "Launch the following code after the controller is implemented"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e89ff6",
   "metadata": {},
   "source": [
    "#### Configuration and arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6daeeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_state = 3\n",
    "dim_input = 2\n",
    "dim_output = dim_state\n",
    "dim_disturb = 0\n",
    "\n",
    "dim_R1 = dim_output + dim_input\n",
    "dim_R2 = dim_R1\n",
    "\n",
    "\"\"\"\n",
    "The parser below is defined in the respective argparser_*.py file\n",
    "You can familiarize yourself with default arguments using this file. \n",
    "Change the code only if you really know what you are doing.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "args = parser.parse_args([])\n",
    "if not isinstance(args.state_init[0], int):\n",
    "    for k in range(len(args.state_init)):\n",
    "        args.state_init[k] = eval( args.state_init[k].replace('pi', str(np.pi)) )\n",
    "\n",
    "args.state_init = np.array(args.state_init)\n",
    "args.action_manual = np.array(args.action_manual)\n",
    "\n",
    "pred_step_size = args.dt * args.pred_step_size_multiplier\n",
    "\n",
    "R1 = np.diag(np.array(args.R1_diag))\n",
    "R2 = np.diag(np.array(args.R2_diag))\n",
    "\n",
    "assert args.t1 > args.dt > 0.0\n",
    "assert args.state_init.size == dim_state\n",
    "\n",
    "globals().update(vars(args))\n",
    "\n",
    "is_disturb = 0\n",
    "is_dyn_ctrl = 0\n",
    "\n",
    "t0 = 0\n",
    "\n",
    "action_init = 0 * np.ones(dim_input)\n",
    "\n",
    "# Solver\n",
    "atol = 1e-5\n",
    "rtol = 1e-3\n",
    "\n",
    "# xy-plane\n",
    "xMin = -10\n",
    "xMax = 10\n",
    "yMin = -10\n",
    "yMax = 10\n",
    "\n",
    "# Control constraints\n",
    "v_min = -25\n",
    "v_max = 25\n",
    "omega_min = -5\n",
    "omega_max = 5\n",
    "ctrl_bnds=np.array([[v_min, v_max], [omega_min, omega_max]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6250870",
   "metadata": {},
   "source": [
    "#### System initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05fed0a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_sys = systems.Sys3WRobotNI(sys_type=\"diff_eqn\",\n",
    "                                     dim_state=dim_state,\n",
    "                                     dim_input=dim_input,\n",
    "                                     dim_output=dim_output,\n",
    "                                     dim_disturb=dim_disturb,\n",
    "                                     pars=[],\n",
    "                                     ctrl_bnds=ctrl_bnds,\n",
    "                                     is_dyn_ctrl=is_dyn_ctrl,\n",
    "                                     is_disturb=is_disturb,\n",
    "                                     pars_disturb=[])\n",
    "\n",
    "observation_init = my_sys.out(state_init)\n",
    "\n",
    "xCoord0 = state_init[0]\n",
    "yCoord0 = state_init[1]\n",
    "alpha0 = state_init[2]\n",
    "alpha_deg_0 = alpha0/2/np.pi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "093ee76e",
   "metadata": {},
   "source": [
    "#### Implemented controller initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a22d697e",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_ctrl_nominal = controllers.CtrlNominal3WRobotNI(ctrl_gain=0.5, ctrl_bnds=ctrl_bnds, t0=t0, sampling_time=dt)\n",
    "\n",
    "# Predictive optimal controller\n",
    "my_ctrl_opt_pred = CtrlOptPred(dim_input=dim_input,\n",
    "                                dim_output=dim_output,\n",
    "                                ctrl_bnds = ctrl_bnds,\n",
    "                                action_init = [],\n",
    "                                t0 = t0,\n",
    "                                sampling_time = dt,\n",
    "                                Nactor = Nactor,\n",
    "                                pred_step_size = pred_step_size,\n",
    "                                sys_rhs = my_sys._state_dyn,\n",
    "                                sys_out = my_sys.out,\n",
    "                                state_sys = state_init,\n",
    "                                prob_noise_pow = prob_noise_pow,\n",
    "                                gamma = gamma,\n",
    "                                stage_obj_struct = stage_obj_struct,\n",
    "                                stage_obj_pars = [R1],\n",
    "                                observation_target = [])\n",
    "\n",
    "my_ctrl_benchm = my_ctrl_opt_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a565533a",
   "metadata": {},
   "source": [
    "#### Loop initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c79458a",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_simulator = simulator.Simulator(sys_type = \"diff_eqn\",\n",
    "                                   closed_loop_rhs = my_sys.closed_loop_rhs,\n",
    "                                   sys_out = my_sys.out,\n",
    "                                   state_init = state_init,\n",
    "                                   disturb_init = [],\n",
    "                                   action_init = action_init,\n",
    "                                   t0 = t0,\n",
    "                                   t1 = t1,\n",
    "                                   dt = dt,\n",
    "                                   max_step = dt/2,\n",
    "                                   first_step = 1e-6,\n",
    "                                   atol = atol,\n",
    "                                   rtol = rtol,\n",
    "                                   is_disturb = is_disturb,\n",
    "                                   is_dyn_ctrl = is_dyn_ctrl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa7bfeb6",
   "metadata": {},
   "source": [
    "#### Setup of experiment design "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed966ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.basename( os.path.normpath( os.path.abspath(os.getcwd()) ) ) == 'presets':\n",
    "    data_folder = '../simdata'\n",
    "else:\n",
    "    data_folder = 'simdata'\n",
    "\n",
    "pathlib.Path(data_folder).mkdir(parents=True, exist_ok=True) \n",
    "\n",
    "date = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "time = datetime.now().strftime(\"%Hh%Mm%Ss\")\n",
    "datafiles = [None] * Nruns\n",
    "\n",
    "for k in range(0, Nruns):\n",
    "    datafiles[k] = data_folder + '/' + my_sys.name + '__' + ctrl_mode + '__' + date + '__' + time + '__run{run:02d}.csv'.format(run=k+1)\n",
    "    \n",
    "    if is_log_data:\n",
    "        print('Logging data to:    ' + datafiles[k])\n",
    "            \n",
    "        with open(datafiles[k], 'w', newline='') as outfile:\n",
    "            writer = csv.writer(outfile)\n",
    "            writer.writerow(['System', my_sys.name ] )\n",
    "            writer.writerow(['Controller', ctrl_mode ] )\n",
    "            writer.writerow(['dt', str(dt) ] )\n",
    "            writer.writerow(['state_init', str(state_init) ] )\n",
    "            writer.writerow(['prob_noise_pow', str(prob_noise_pow) ] )\n",
    "            writer.writerow(['Nactor', str(Nactor) ] )\n",
    "            writer.writerow(['pred_step_size_multiplier', str(pred_step_size_multiplier) ] )\n",
    "            writer.writerow(['stage_obj_struct', str(stage_obj_struct) ] )\n",
    "            writer.writerow(['R1_diag', str(R1_diag) ] )\n",
    "            writer.writerow(['R2_diag', str(R2_diag) ] )\n",
    "            writer.writerow(['gamma', str(gamma) ] )\n",
    "            writer.writerow(['actor_struct', str(actor_struct) ] )   \n",
    "            writer.writerow(['t [s]', 'x [m]', 'y [m]', 'alpha [rad]', 'stage_obj', 'accum_obj', 'v [m/s]', 'omega [rad/s]'] )\n",
    "\n",
    "if is_print_sim_step:\n",
    "    warnings.filterwarnings('ignore')\n",
    "    \n",
    "my_logger = loggers.Logger3WRobotNI()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbcb9fd6",
   "metadata": {},
   "source": [
    "### 2.2 Main loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e38bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_trajectory = []\n",
    "if is_visualization:\n",
    "    \n",
    "    state_full_init = my_simulator.state_full\n",
    "    \n",
    "    my_animator = visuals.Animator3WRobotNI(objects=(my_simulator,\n",
    "                                                     my_sys,\n",
    "                                                     my_ctrl_nominal,\n",
    "                                                     my_ctrl_benchm,\n",
    "                                                     datafiles,\n",
    "                                                     controllers.ctrl_selector,\n",
    "                                                     my_logger),\n",
    "                                            pars=(state_init,\n",
    "                                                  action_init,\n",
    "                                                  t0,\n",
    "                                                  t1,\n",
    "                                                  state_full_init,\n",
    "                                                  xMin,\n",
    "                                                  xMax,\n",
    "                                                  yMin,\n",
    "                                                  yMax,\n",
    "                                                  ctrl_mode,\n",
    "                                                  action_manual,\n",
    "                                                  v_min,\n",
    "                                                  omega_min,\n",
    "                                                  v_max,\n",
    "                                                  omega_max,\n",
    "                                                  Nruns,\n",
    "                                                    is_print_sim_step, is_log_data, 0, []))\n",
    "\n",
    "    anm = animation.FuncAnimation(my_animator.fig_sim,\n",
    "                                  my_animator.animate,\n",
    "                                  init_func=my_animator.init_anim,\n",
    "                                  blit=False, interval=dt/1e6, repeat=False)\n",
    "    \n",
    "    my_animator.get_anm(anm)\n",
    "    \n",
    "    cId = my_animator.fig_sim.canvas.mpl_connect('key_press_event', lambda event: on_key_press(event, anm))\n",
    "    \n",
    "    anm.running = True\n",
    "    \n",
    "    my_animator.fig_sim.tight_layout()\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "else:   \n",
    "    run_curr = 1\n",
    "    datafile = datafiles[0]\n",
    "    \n",
    "    while True:\n",
    "        \n",
    "        my_simulator.sim_step()\n",
    "        \n",
    "        t, state, observation, state_full = my_simulator.get_sim_step_data()\n",
    "        \n",
    "        action = controllers.ctrl_selector(t, observation, action_manual, my_ctrl_nominal, my_ctrl_benchm, ctrl_mode)\n",
    "        \n",
    "        my_sys.receive_action(action)\n",
    "        my_ctrl_benchm.receive_sys_state(my_sys._state)\n",
    "        my_ctrl_benchm.upd_accum_obj(observation, action)\n",
    "        \n",
    "        xCoord = state_full[0]\n",
    "        yCoord = state_full[1]\n",
    "        alpha = state_full[2]\n",
    "        trajectory.append([xCoord, yCoord, alpha])\n",
    "        \n",
    "        stage_obj = my_ctrl_benchm.stage_obj(observation, action)\n",
    "        accum_obj = my_ctrl_benchm.accum_obj_val\n",
    "        if is_print_sim_step:\n",
    "            my_logger.print_sim_step(t, xCoord, yCoord, alpha, stage_obj, accum_obj, action)\n",
    "            \n",
    "        if is_log_data:\n",
    "            my_logger.log_data_row(datafile, t, xCoord, yCoord, alpha, stage_obj, accum_obj, action)\n",
    "        \n",
    "        if t >= t1:  \n",
    "            if is_print_sim_step:\n",
    "                print('.....................................Run {run:2d} done.....................................'.format(run = run_curr))\n",
    "                \n",
    "            run_curr += 1\n",
    "            \n",
    "            if run_curr > Nruns:\n",
    "                break\n",
    "                \n",
    "            if is_log_data:\n",
    "                datafile = datafiles[run_curr-1]\n",
    "            \n",
    "            # Reset simulator\n",
    "            my_simulator.status = 'running'\n",
    "            my_simulator.t = t0\n",
    "            my_simulator.observation = state_full_init\n",
    "            \n",
    "            if ctrl_mode != 'nominal':\n",
    "                my_ctrl_benchm.reset(t0)\n",
    "            else:\n",
    "                my_ctrl_nominal.reset(t0)\n",
    "            \n",
    "            accum_obj = 0  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9066ea0a",
   "metadata": {},
   "source": [
    "### <font color=\"orange\">Auto-grading</font>\n",
    "\n",
    "Run this cell to track your answers. Make sure you defined the `first_name` and `second_name` variables to avoid a `NameError` below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34098df",
   "metadata": {},
   "outputs": [],
   "source": [
    "### GRADING DO NOT MODIFY\n",
    "assignment_name = \"MPC_controller_implementation\"\n",
    "first_name = \"Ivan\"\n",
    "last_name = \"Ivanov\"\n",
    "asgn2_answers = AnswerTracker()\n",
    "asgn1_answers.record('problem_1', {'trajectory': full_trajectory})\\\n",
    "                .save_to_json(assignment_name, first_name, last_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "625fde78",
   "metadata": {},
   "source": [
    "## Questions?\n",
    "\n",
    "Reach out to Ilya Osokin (@elijahmipt) or Georgiy Malaniya (@odinmaniac) on Telegram."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa6c80fc",
   "metadata": {},
   "source": [
    "## Sources\n",
    "\n",
    " ***\n",
    " **<sup>[1]</sup> Bertsekas, D. , Reinforcement Learning and Optimal Control**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d73451d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
